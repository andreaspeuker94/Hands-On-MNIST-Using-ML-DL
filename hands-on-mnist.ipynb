{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Hands-on MNIST using Machine Learning and Deep Learning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Exploration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist['data'], mnist['target']\n",
    "\n",
    "print(X.shape, y.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Unique Labels:')\n",
    "y.value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Label-Balance (in %):')\n",
    "y.value_counts()/len(y)*100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "digit_index = 0\n",
    "\n",
    "digit = X.values[digit_index].reshape(28,28)\n",
    "plt.imshow(digit, cmap='binary')\n",
    "plt.show()\n",
    "\n",
    "print('Label:', y[digit_index])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def normalize(data):\n",
    "    return data/255 # Alternatively, you can use sklearn's MinMax Scaler. For other feature scaling tasks, you would normally use StandardScaler\n",
    "\n",
    "X_train_normalized = normalize(X_train)\n",
    "X_test_normalized = normalize(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Machine Learning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Selection using Cross-Validation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Just a few Classifier, add more if you want!\n",
    "estimators = [\n",
    "    DecisionTreeClassifier(), \n",
    "    RandomForestClassifier()\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "CV = 5 # Fold\n",
    "SCORING = 'f1_macro' # Validation Metric (others: accuracy, precision, recall, ...)\n",
    "\n",
    "scores = [cross_val_score(estimator=estimator, X=X_train_normalized, y=y_train, cv=CV, scoring=SCORING).mean() for estimator in tqdm(estimators) ]\n",
    "best_estimator = estimators[scores.index(max(scores))]\n",
    "best_score = max(scores)\n",
    "\n",
    "print(best_estimator, best_score)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter-Tuning using GridSearchCV"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "PARAM_GRID = ''\n",
    "\n",
    "# Example Parameter Grid for a Random Forest Classifier and a Decicion Tree\n",
    "if type(best_estimator) == type(RandomForestClassifier()):\n",
    "    PARAM_GRID = [\n",
    "        {'n_estimators':[3,10,30,100], 'max_features': [2,4]},\n",
    "        {'bootstrap':[False], 'n_estimators':[3,10,30,100], 'max_features': [2,4]}\n",
    "    ]\n",
    "\n",
    "elif type(best_estimator) == type(DecisionTreeClassifier()): \n",
    "    PARAM_GRID = [\n",
    "        {'criterion': ['gini', 'entropy'], 'max_depth': [2,4,6,8,10,12]}\n",
    "    ]\n",
    "\n",
    "estimator_cv = GridSearchCV(estimator=best_estimator, param_grid=PARAM_GRID, scoring=SCORING, cv=CV)\n",
    "search_result = estimator_cv.fit(X=X_train_normalized, y=y_train)\n",
    "\n",
    "print(search_result.best_estimator_, search_result.best_score_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validate final Model based on Test-Set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "final_ML_model = search_result.best_estimator_\n",
    "final_predictions = final_ML_model.predict(X_test_normalized)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "digit_index = 5\n",
    "\n",
    "digit = X_test_normalized.values[digit_index].reshape(28,28)\n",
    "plt.imshow(digit, cmap='binary')\n",
    "plt.show()\n",
    "\n",
    "print('Label:', y_test.values[digit_index])\n",
    "print('Prediction:', final_predictions[digit_index])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "accuracy_score(final_predictions, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classification_report(final_predictions, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "matrix = confusion_matrix(final_predictions, y_test)\n",
    "ax = sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues')\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('True Label')\n",
    "ax.set_title('Confusion Matrix')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "'''\n",
    "NOTE: Over- and Underfitting\n",
    "Score of cross validation on train is good but not on test set: Model probably overfits the data \n",
    "Solution: Try with a less complex model to prevent overfitting\n",
    "\n",
    "Score of cross validation on train AND test set is bad: Model probably underfits/generalizes the data OR data quality is bad\n",
    "Solution: Try with a more complex model AND/OR collect more data/features\n",
    "'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import joblib\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "now = str(datetime.now().strftime(\"%Y-%m-%d_%H:%M\"))\n",
    "filename = 'ML_model-{now}.pkl'.format(**locals())\n",
    "\n",
    "joblib.dump(final_ML_model, 'models/machine_learning/'+filename)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Neural Networks (Deep Learning)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Neural Network with Fully-Connected/Dense Layers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer, Dense\n",
    "import tensorflow as tf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "INPUT_SHAPE = [X_train_normalized.shape[1]] # Number of values per dimension (Number of Features)\n",
    "OUTPUT_NEURONS = len(y.unique()) # Number of output neurons / label classes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def build_model(n_hidden=4, n_neurons=8):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=INPUT_SHAPE))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(Dense(n_neurons, activation='relu'))\n",
    "    model.add(Dense(OUTPUT_NEURONS, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # Note: Using categorical_crossentropy for (any) classification task (you can also use activation='sigmoid' and loss='binary_crossentropy' for binary classification)\n",
    "    return model\n",
    "\n",
    "neural_net = KerasClassifier(build_fn=build_model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "param_grid = {\n",
    "    'n_hidden': [2,4,6],\n",
    "    'n_neurons': [50,100,150,200,300,400]\n",
    "}\n",
    "\n",
    "N_ITER = 10\n",
    "EPOCHS = 50\n",
    "CV = 5\n",
    "\n",
    "# Note: GridSearchCV would take a long time. Therefore, we use RandomizedSearchCV to tune the Hyperparameters of the Neural Net. However, my experiences show, that 4 hidden layers with 300 neurons do a great job\n",
    "neural_net_cv = RandomizedSearchCV(estimator=neural_net, param_distributions=param_grid, n_iter=N_ITER, cv=CV)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=5) # Monitor Validation Loss and stop Training when Validation Loss starts increasing the <patience> time/number of epochs\n",
    "neural_result = neural_net_cv.fit(X=X_train_normalized, y=y_train, validation_split=0.1, callbacks=[early_stopping], epochs=EPOCHS, verbose=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "final_NN_model = neural_result.best_estimator_\n",
    "print(neural_result.best_estimator_, neural_result.best_params_, neural_result.best_score_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "final_predictions = final_NN_model.predict(X_test_normalized)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "digit_index = 5\n",
    "\n",
    "digit = X_test_normalized.values[digit_index].reshape(28,28)\n",
    "plt.imshow(digit, cmap='binary')\n",
    "plt.show()\n",
    "\n",
    "print('Label:', y_test.values[digit_index])\n",
    "print('Prediction:', final_predictions[digit_index])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Validate final Model based on Test-Set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "accuracy_score(y_pred=final_predictions, y_true=y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classification_report(y_pred=final_predictions, y_true=y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "confusion_matrix(final_predictions, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "now = str(datetime.now().strftime(\"%Y-%m-%d_%H:%M\"))\n",
    "filename = 'NN_model-{now}'.format(**locals())\n",
    "\n",
    "# Saving Architecture\n",
    "open('models/neural_networks/'+filename+'.json', 'w').write(final_NN_model.model.to_json())\n",
    "# Saving Weights\n",
    "final_NN_model.model.save_weights('models/neural_networks/'+filename+'.h5', overwrite=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predict new Images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load latest Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import joblib\n",
    "from keras.models import model_from_json"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_latest_models():\n",
    "    # Load latest ML Model\n",
    "    MLmodels_all = glob('models/machine_learning/*pkl')\n",
    "    MLmodel = joblib.load(max(MLmodels_all, key=os.path.getctime))\n",
    "\n",
    "    # Load latest Neural Network\n",
    "    PATH = 'models/neural_networks/'\n",
    "    NNmodels_architectures = glob(PATH + '*json') # Latest architectures\n",
    "    NNmodels_weights= glob(PATH+'*h5') # Latest weights\n",
    "    NNmodel = model_from_json(open(max(NNmodels_architectures, key=os.path.getctime)).read())\n",
    "    NNmodel.load_weights(max(NNmodels_weights, key=os.path.getctime))\n",
    "    NNmodel.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    return MLmodel, NNmodel\n",
    "\n",
    "final_ML_model, final_NN_model = get_latest_models()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare new Image"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def prepare_new_image(file_path, print_digit=True):\n",
    "    digit_array = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    digit_array = cv2.bitwise_not(digit_array)\n",
    "    digit_array_resized = cv2.resize(digit_array, (28,28))\n",
    "\n",
    "    digit_reshaped = digit_array_resized.reshape(784)\n",
    "    digit_normalized = normalize(digit_reshaped)\n",
    "\n",
    "    if print_digit:\n",
    "        _, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        ax1.imshow(digit_array, cmap=plt.cm.binary)\n",
    "        ax1.set_title('Original')\n",
    "        ax2.imshow(digit_array_resized, cmap=plt.cm.binary)\n",
    "        ax2.set_title('Resized')\n",
    "\n",
    "    return digit_normalized\n",
    "\n",
    "digit_normalized = prepare_new_image('digits/4.png', print_digit=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predict"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Prediction using trained Machine Learning Model\n",
    "predicted_instance_ML = final_ML_model.predict_proba([digit_normalized])\n",
    "print('ML Model (', type(final_ML_model), '):')\n",
    "print('Predicted Class:', int(np.argmax(predicted_instance_ML, axis=1)))\n",
    "print('Probabilities:', predicted_instance_ML)\n",
    "\n",
    "# Prediction using trained Neural Network\n",
    "predicted_instance_NN = final_NN_model.predict([digit_normalized.tolist()])\n",
    "print('Neural Network:')\n",
    "print('Predicted Class', int(np.argmax(predicted_instance_NN, axis=1)))\n",
    "print('Probabilities:', predicted_instance_NN)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('mnist_toolkit': conda)"
  },
  "interpreter": {
   "hash": "dbbd4f8e447fdf2200cb1b2485d2404aac0df375c997697d86d68254c74edff3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}