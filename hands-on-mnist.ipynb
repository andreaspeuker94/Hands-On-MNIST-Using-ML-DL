{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Hands-on MNIST using Machine Learning and Deep Learning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Exploration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist['data'], mnist['target']\n",
    "\n",
    "print(X.shape, y.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Unique Labels:')\n",
    "y.value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Label-Balance (in %):')\n",
    "y.value_counts()/len(y)*100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "digit_index = 0\n",
    "\n",
    "digit = X.values[digit_index].reshape(28,28)\n",
    "plt.imshow(digit, cmap='binary')\n",
    "plt.show()\n",
    "\n",
    "print('Label:', y[digit_index])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def normalize(data):\n",
    "    return data/255 # Alternatively, you can use sklearn's MinMax Scaler. For other feature scaling tasks, you would normally use StandardScaler\n",
    "\n",
    "X_train_normalized = normalize(X_train)\n",
    "X_test_normalized = normalize(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Machine Learning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Selection using Cross-Validation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Just a few Classifier, add more if you want!\n",
    "estimators = [\n",
    "    DecisionTreeClassifier(), \n",
    "    RandomForestClassifier()\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "CV = 5 # Fold\n",
    "SCORING = 'f1_macro' # Validation Metric (others: accuracy, precision, recall, ...)\n",
    "\n",
    "scores = [cross_val_score(estimator=estimator, X=X_train_normalized, y=y_train, cv=CV, scoring=SCORING).mean() for estimator in tqdm(estimators) ]\n",
    "best_estimator = estimators[scores.index(max(scores))]\n",
    "best_score = max(scores)\n",
    "\n",
    "print(best_estimator, best_score)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter-Tuning using GridSearchCV"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "PARAM_GRID = ''\n",
    "\n",
    "# Example Parameter Grid for a Random Forest Classifier and a Decicion Tree\n",
    "if type(best_estimator) == type(RandomForestClassifier()):\n",
    "    PARAM_GRID = [\n",
    "        {'n_estimators':[3,10,30,100], 'max_features': [2,4]},\n",
    "        {'bootstrap':[False], 'n_estimators':[3,10,30,100], 'max_features': [2,4]}\n",
    "    ]\n",
    "\n",
    "elif type(best_estimator) == type(DecisionTreeClassifier()): \n",
    "    PARAM_GRID = [\n",
    "        {'criterion': ['gini', 'entropy'], 'max_depth': [2,4,6,8,10,12]}\n",
    "    ]\n",
    "\n",
    "estimator_cv = GridSearchCV(estimator=best_estimator, param_grid=PARAM_GRID, scoring=SCORING, cv=CV)\n",
    "search_result = estimator_cv.fit(X=X_train_normalized, y=y_train)\n",
    "\n",
    "print(search_result.best_estimator_, search_result.best_score_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validate final Model based on Test-Set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "final_ML_model = search_result.best_estimator_\n",
    "final_predictions = final_ML_model.predict(X_test_normalized)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "digit_index = 5\n",
    "\n",
    "digit = X_test_normalized.values[digit_index].reshape(28,28)\n",
    "plt.imshow(digit, cmap='binary')\n",
    "plt.show()\n",
    "\n",
    "print('Label:', y_test.values[digit_index])\n",
    "print('Prediction:', final_predictions[digit_index])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "accuracy_score(final_predictions, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classification_report(final_predictions, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "matrix = confusion_matrix(final_predictions, y_test)\n",
    "ax = sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues')\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('True Label')\n",
    "ax.set_title('Confusion Matrix')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "'''\n",
    "NOTE: Over- and Underfitting\n",
    "Score of cross validation on train is good but not on test set: Model probably overfits the data \n",
    "Solution: Try with a less complex model to prevent overfitting\n",
    "\n",
    "Score of cross validation on train AND test set is bad: Model probably underfits/generalizes the data OR data quality is bad\n",
    "Solution: Try with a more complex model AND/OR collect more data/features\n",
    "'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import joblib\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "now = str(datetime.now().strftime(\"%Y-%m-%d_%H:%M\"))\n",
    "filename = 'ML_model-{now}.pkl'.format(**locals())\n",
    "\n",
    "joblib.dump(final_ML_model, 'models/machine_learning/'+filename)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Neural Networks (Deep Learning)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer, Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "import tensorflow as tf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Neural Network with Fully-Connected (FC) Layers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "INPUT_SHAPE = [X_train_normalized.shape[1]] # Number of values per dimension (Number of Features)\n",
    "OUTPUT_NEURONS = len(y.unique()) # Number of output neurons / label classes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def build_model(n_hidden=4, n_neurons=8, dropout_rate=0.5):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=INPUT_SHAPE))\n",
    "    model.add(Dropout(rate=dropout_rate))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(Dense(n_neurons, activation='relu'))\n",
    "        model.add(Dropout(rate=dropout_rate))\n",
    "    model.add(Dense(OUTPUT_NEURONS, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # Note: Using categorical_crossentropy for (any) classification task (you can also use activation='sigmoid' and loss='binary_crossentropy' for binary classification)\n",
    "    return model\n",
    "\n",
    "FC_neural_net = KerasClassifier(build_fn=build_model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "param_grid = {\n",
    "    'n_hidden': [2,4,6],\n",
    "    'n_neurons': [50,100,150,200,300,400],\n",
    "    'dropout_rate': [0.0,0.2,0.5,0.7]\n",
    "}\n",
    "\n",
    "N_ITER = 5\n",
    "EPOCHS = 50\n",
    "CV = 5\n",
    "\n",
    "# Note: GridSearchCV would take a long time. Therefore, we use RandomizedSearchCV to tune the Hyperparameters of the Neural Net. However, my experiences show, that 2 hidden layers, 150  neurons and a dropout of 0.2 do a great job (98% Accuracy)\n",
    "FC_neural_net_cv = RandomizedSearchCV(estimator=FC_neural_net, param_distributions=param_grid, n_iter=N_ITER, cv=CV)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=5) # Monitor Validation Loss and stop Training when Validation Loss starts increasing the <patience> time/number of epochs\n",
    "FC_neural_net_cv_result = FC_neural_net_cv.fit(X=X_train_normalized, y=y_train, validation_split=0.1, callbacks=[early_stopping], epochs=EPOCHS, verbose=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "final_FC_model = FC_neural_net_cv_result.best_estimator_\n",
    "print(FC_neural_net_cv_result.best_estimator_, FC_neural_net_cv_result.best_params_, FC_neural_net_cv_result.best_score_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "FC_final_predictions = final_FC_model.predict(X_test_normalized)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "digit_index = 5\n",
    "\n",
    "digit = X_test_normalized.values[digit_index].reshape(28,28)\n",
    "plt.imshow(digit, cmap='binary')\n",
    "plt.show()\n",
    "\n",
    "print('Label:', y_test.values[digit_index])\n",
    "print('Prediction:', FC_final_predictions[digit_index])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Validate final Model based on Test-Set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "accuracy_score(y_pred=FC_final_predictions, y_true=y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classification_report(y_pred=FC_final_predictions, y_true=y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "matrix = confusion_matrix(FC_final_predictions, y_test)\n",
    "ax = sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues')\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('True Label')\n",
    "ax.set_title('Confusion Matrix')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "now = str(datetime.now().strftime(\"%Y-%m-%d_%H:%M\"))\n",
    "filename = 'FC-{now}'.format(**locals())\n",
    "\n",
    "# Saving Architecture\n",
    "open('models/fully_connected/'+filename+'.json', 'w').write(final_FC_model.model.to_json())\n",
    "# Saving Weights\n",
    "final_FC_model.model.save_weights('models/fully_connected/'+filename+'.h5', overwrite=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convolutional Neural Network (CNN)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train_normalized_reshaped = [a.reshape(28,28,1) for a in X_train_normalized.values]\n",
    "X_train_normalized_reshaped = np.asarray(X_train_normalized_reshaped)\n",
    "\n",
    "X_test_normalized_reshaped = [a.reshape(28,28,1) for a in X_test_normalized.values]\n",
    "X_test_normalized_reshaped = np.asarray(X_test_normalized_reshaped)\n",
    "\n",
    "INPUT_SHAPE = X_train_normalized_reshaped[0].shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def build_cnn(n_neurons_dense=100, kernel_size=(3,3), filter_size=32, pooling_size=(2,2), dropout_rate=0.5):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filter_size, kernel_size=kernel_size, activation='relu', input_shape=INPUT_SHAPE))\n",
    "    model.add(MaxPooling2D(pool_size=pooling_size))\n",
    "\n",
    "    model.add(Conv2D(filter_size, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pooling_size))\n",
    "    model.add(Dropout(rate=dropout_rate))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_neurons_dense, activation='relu'))\n",
    "    model.add(Dropout(rate=dropout_rate))\n",
    "    model.add(Dense(OUTPUT_NEURONS, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "CNN_neural_net = KerasClassifier(build_fn=build_cnn)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "param_grid = {\n",
    "    'n_neurons_dense': [50,100,150,200,300,400],\n",
    "    'kernel_size': [(2,2),(3,3),(4,4)],\n",
    "    'filter_size': [10,32,50,100,200],\n",
    "    'pooling_size': [(2,2),(3,3),(4,4)],\n",
    "    'dropout_rate': [0.0,0.2,0.5,0.7]\n",
    "}\n",
    "\n",
    "N_ITER = 5\n",
    "EPOCHS = 50\n",
    "CV = 5\n",
    "\n",
    "# Note: GridSearchCV would take a long time. Therefore, we use RandomizedSearchCV to tune the Hyperparameters of the CNN. However, my experiences show, that 'pooling_size': (2, 2), 'n_neurons_dense': 300, 'n_hidden': 6, 'kernel_size': (3, 3), 'filter_size': 50, 'dropout_rate': 0.5 do a great job (99,11% Accuracy)\n",
    "CNN_neural_net_cv = RandomizedSearchCV(estimator=CNN_neural_net, param_distributions=param_grid, n_iter=N_ITER, cv=CV)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=5) # Monitor Validation Loss and stop Training when Validation Loss starts increasing the <patience> time/number of epochs\n",
    "CNN_neural_net_cv_result = CNN_neural_net_cv.fit(X=X_train_normalized_reshaped, y=y_train, validation_split=0.1, callbacks=[early_stopping], epochs=EPOCHS, verbose=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "CNN_final_model = CNN_neural_net_cv_result.best_estimator_\n",
    "print(CNN_neural_net_cv_result.best_estimator_, CNN_neural_net_cv_result.best_params_, CNN_neural_net_cv_result.best_score_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "CNN_final_predictions = CNN_final_model.predict(X_test_normalized_reshaped)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "digit_index = 5\n",
    "\n",
    "digit = X_test_normalized_reshaped[digit_index]\n",
    "plt.imshow(digit, cmap='binary')\n",
    "plt.show()\n",
    "\n",
    "print('Label:', y_test.values[digit_index])\n",
    "print('Prediction:', CNN_final_predictions[digit_index])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Validate final Model based on Test-Set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "accuracy_score(y_pred=CNN_final_predictions, y_true=y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classification_report(y_pred=CNN_final_predictions, y_true=y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "matrix = confusion_matrix(CNN_final_predictions, y_test)\n",
    "ax = sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues')\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('True Label')\n",
    "ax.set_title('Confusion Matrix')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "now = str(datetime.now().strftime(\"%Y-%m-%d_%H:%M\"))\n",
    "filename = 'CNN-{now}'.format(**locals())\n",
    "\n",
    "# Saving Architecture\n",
    "open('models/cnn/'+filename+'.json', 'w').write(CNN_final_model.model.to_json())\n",
    "# Saving Weights\n",
    "CNN_final_model.model.save_weights('models/cnn/'+filename+'.h5', overwrite=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predict new Images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load latest Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import joblib\n",
    "from keras.models import model_from_json"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_latest_models():\n",
    "    # Load latest ML Model\n",
    "    MLmodels_all = glob('models/machine_learning/*pkl')\n",
    "    MLmodel = joblib.load(max(MLmodels_all, key=os.path.getctime))\n",
    "\n",
    "    # Load latest Fully Connected Neural Network\n",
    "    PATH = 'models/fully_connected/'\n",
    "    FC_architectures = glob(PATH + '*json') # Latest architectures\n",
    "    FC_weights= glob(PATH+'*h5') # Latest weights\n",
    "    FCmodel = model_from_json(open(max(FC_architectures, key=os.path.getctime)).read())\n",
    "    FCmodel.load_weights(max(FC_weights, key=os.path.getctime))\n",
    "    FCmodel.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "    # Load latest CNN\n",
    "    PATH = 'models/cnn/'\n",
    "    CNN_architectures = glob(PATH + '*json') # Latest architectures\n",
    "    CNN_weights= glob(PATH+'*h5') # Latest weights\n",
    "    CNNmodel = model_from_json(open(max(CNN_architectures, key=os.path.getctime)).read())\n",
    "    CNNmodel.load_weights(max(CNN_weights, key=os.path.getctime))\n",
    "    CNNmodel.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "    return MLmodel, FCmodel, CNNmodel\n",
    "\n",
    "final_ML_model, final_FC_model, final_CNN_model = get_latest_models()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare new Image"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def prepare_new_image(file_path, print_digit=True):\n",
    "    digit_array = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    digit_array = cv2.bitwise_not(digit_array)\n",
    "    digit_array_resized = cv2.resize(digit_array, (28,28))\n",
    "\n",
    "    digit_reshaped = digit_array_resized.reshape(784)\n",
    "    digit_normalized = normalize(digit_reshaped)\n",
    "\n",
    "    if print_digit:\n",
    "        _, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        ax1.imshow(digit_array, cmap=plt.cm.binary)\n",
    "        ax1.set_title('Original')\n",
    "        ax2.imshow(digit_array_resized, cmap=plt.cm.binary)\n",
    "        ax2.set_title('Resized')\n",
    "\n",
    "    return digit_normalized\n",
    "\n",
    "digit_normalized = prepare_new_image('digits/3.png', print_digit=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predict"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Prediction using trained Machine Learning Model\n",
    "ML_predicted_instance = final_ML_model.predict_proba([digit_normalized])\n",
    "print('ML Model (', type(final_ML_model), '):')\n",
    "print('Predicted Class:', int(np.argmax(ML_predicted_instance, axis=1)))\n",
    "print('Probabilities:', ML_predicted_instance)\n",
    "\n",
    "# Prediction using trained Neural Network\n",
    "FC_predicted_instance = final_FC_model.predict([digit_normalized.tolist()])\n",
    "print('Fully Connected Neural Network:')\n",
    "print('Predicted Class', int(np.argmax(FC_predicted_instance, axis=1)))\n",
    "print('Probabilities:', FC_predicted_instance)\n",
    "\n",
    "# Prediction using trained CNN\n",
    "CNN_predicted_instance = final_CNN_model.predict([digit_normalized.reshape(28,28,1).tolist()])\n",
    "print('Convolutional Neural Network:')\n",
    "print('Predicted Class', int(np.argmax(CNN_predicted_instance, axis=1)))\n",
    "print('Probabilities:', CNN_predicted_instance)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('mnist_toolkit': conda)"
  },
  "interpreter": {
   "hash": "dbbd4f8e447fdf2200cb1b2485d2404aac0df375c997697d86d68254c74edff3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}